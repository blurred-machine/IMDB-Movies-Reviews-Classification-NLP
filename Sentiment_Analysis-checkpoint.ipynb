{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\paras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet \n",
    "allEnglishWords = words.words() + [w for w in wordnet.words()]\n",
    "allEnglishWords = np.unique([x.lower() for x in allEnglishWords])\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"aclImdb/\"\n",
    "positiveFiles = [x for x in os.listdir(path+\"train/pos/\") if x.endswith(\".txt\")]\n",
    "negativeFiles = [x for x in os.listdir(path+\"train/neg/\") if x.endswith(\".txt\")]\n",
    "testFiles1 = [x for x in os.listdir(path+\"test/pos/\") if x.endswith(\".txt\")]\n",
    "testFiles2 = [x for x in os.listdir(path+\"test/neg/\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testFiles2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveReviews, negativeReviews, pos_testReviews, neg_testReviews = [], [], [], []\n",
    "for pfile in positiveFiles:\n",
    "    with open(path+\"train/pos/\"+pfile, encoding=\"latin1\") as f:\n",
    "        positiveReviews.append(f.read())\n",
    "for nfile in negativeFiles:\n",
    "    with open(path+\"train/neg/\"+nfile, encoding=\"latin1\") as f:\n",
    "        negativeReviews.append(f.read())\n",
    "for tfile in testFiles1:\n",
    "    with open(path+\"test/pos/\"+tfile, encoding=\"latin1\") as f:\n",
    "        pos_testReviews.append(f.read())\n",
    "for tfile in testFiles2:\n",
    "    with open(path+\"test/neg/\"+tfile,encoding=\"latin1\") as f:\n",
    "        neg_testReviews.append(f.read())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-68eda3f1e726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reviews' is not defined"
     ]
    }
   ],
   "source": [
    "reviews_train = pd.concat([\n",
    "    pd.DataFrame({\"review\":positiveReviews, \"label\":1, \"file\":positiveFiles}),\n",
    "    pd.DataFrame({\"review\":negativeReviews, \"label\":0, \"file\":negativeFiles})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)\n",
    "\n",
    "\n",
    "#test set \n",
    "reviews_test= pd.concat([\n",
    "     pd.DataFrame({\"review\":pos_testReviews, \"label\":1, \"file\":testFiles1}),\n",
    "    pd.DataFrame({\"review\":neg_testReviews, \"label\":0, \"file\":testFiles2})\n",
    "], ignore_index=True).sample(frac=1, random_state=1)\n",
    "\n",
    "\n",
    "print(reviews_train.head())\n",
    "print(reviews_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything centralized in 1 dataframe, we now perform train, validation and test set splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews = reviews[[\"review\", \"label\", \"file\"]].sample(frac=1, random_state=1)\n",
    "#train = reviews[reviews.label!=-1].sample(frac=0.8, random_state=1)\n",
    "#valid = reviews[reviews.label!=-1].drop(train.index)\n",
    "#test = reviews[reviews.label==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train.shape)\n",
    "#print(valid.shape)\n",
    "#print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(reviews_train.review.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "It can perform the following operations.\n",
    "* Discard non alpha-numeric characters\n",
    "* Set everything to lower case\n",
    "* Stems all words using PorterStemmer, and change the stems back to the most occurring existent word.\n",
    "* Discard non-Egnlish words (not by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    ''' Preprocess data for NLP tasks. '''\n",
    "\n",
    "    def __init__(self, alpha=True, lower=True, stemmer=True, english=False):\n",
    "        self.alpha = alpha\n",
    "        self.lower = lower\n",
    "        self.stemmer = stemmer\n",
    "        self.english = english\n",
    "        \n",
    "        self.uniqueWords = None\n",
    "        self.uniqueStems = None\n",
    "        \n",
    "    def fit(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "\n",
    "        allwords = pd.DataFrame({\"word\": np.concatenate(texts.apply(lambda x: x.split()).values)})\n",
    "        self.uniqueWords = allwords.groupby([\"word\"]).size().rename(\"count\").reset_index()\n",
    "        self.uniqueWords = self.uniqueWords[self.uniqueWords[\"count\"]>1]\n",
    "        if self.stemmer:\n",
    "            self.uniqueWords[\"stem\"] = self.uniqueWords.word.apply(lambda x: PorterStemmer().stem(x)).values\n",
    "            self.uniqueWords.sort_values([\"stem\", \"count\"], inplace=True, ascending=False)\n",
    "            self.uniqueStems = self.uniqueWords.groupby(\"stem\").first()\n",
    "        \n",
    "        #if self.english: self.words[\"english\"] = np.in1d(self.words[\"mode\"], allEnglishWords)\n",
    "        print(\"Fitted.\")\n",
    "            \n",
    "    def transform(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "        if self.stemmer:\n",
    "            allwords = np.concatenate(texts.apply(lambda x: x.split()).values)\n",
    "            uniqueWords = pd.DataFrame(index=np.unique(allwords))\n",
    "            uniqueWords[\"stem\"] = pd.Series(uniqueWords.index).apply(lambda x: PorterStemmer().stem(x)).values\n",
    "            uniqueWords[\"mode\"] = uniqueWords.stem.apply(lambda x: self.uniqueStems.loc[x, \"word\"] if x in self.uniqueStems.index else \"\")\n",
    "            texts = texts.apply(lambda x: \" \".join([uniqueWords.loc[y, \"mode\"] for y in x.split()]))\n",
    "        #if self.english: texts = self.words.apply(lambda x: \" \".join([y for y in x.split() if self.words.loc[y,\"english\"]]))\n",
    "        print(\"Transformed.\")\n",
    "        return(texts)\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        texts = self._doAlways(texts)\n",
    "        self.fit(texts)\n",
    "        texts = self.transform(texts)\n",
    "        return(texts)\n",
    "    \n",
    "    def _doAlways(self, texts):\n",
    "        # Remove parts between <>'s\n",
    "        texts = texts.apply(lambda x: re.sub('<.*?>', ' ', x))\n",
    "        # Keep letters and digits only.\n",
    "        if self.alpha: texts = texts.apply(lambda x: re.sub('[^a-zA-Z0-9 ]+', ' ', x))\n",
    "        # Set everything to lower case\n",
    "        if self.lower: texts = texts.apply(lambda x: x.lower())\n",
    "        return texts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21492</th>\n",
       "      <td>I have copy of this on VHS, I think they (The ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6844_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>After several extremely well ratings to the po...</td>\n",
       "      <td>1</td>\n",
       "      <td>7290_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933</th>\n",
       "      <td>I still don't know why I forced myself to sit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2740_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>Mt little sister and I are self-proclaimed hor...</td>\n",
       "      <td>0</td>\n",
       "      <td>10094_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>I have personally seen many Disney movies in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>6150_7.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file\n",
       "21492  I have copy of this on VHS, I think they (The ...      0   6844_1.txt\n",
       "9488   After several extremely well ratings to the po...      1  7290_10.txt\n",
       "16933  I still don't know why I forced myself to sit ...      0   2740_1.txt\n",
       "12604  Mt little sister and I are self-proclaimed hor...      0  10094_1.txt\n",
       "8222   I have personally seen many Disney movies in m...      1   6150_7.txt"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocessor(alpha=True, lower=True, stemmer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted.\n",
      "Transformed.\n",
      "Fitted.\n",
      "Transformed.\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainX = preprocess.fit_transform(reviews_train.review)\n",
    "testX =preprocess.fit_transform(reviews_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21492    i have copy of this on vhs i think they the te...\n",
       "9488     after several extremely well rating to the poi...\n",
       "16933    i still don t know why i forced myself to sit ...\n",
       "12604    mt little sister and i are self proclaimed hor...\n",
       "8222     i have person seen many disney movie in my lif...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46433, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18412</th>\n",
       "      <td>disappointingly</td>\n",
       "      <td>24</td>\n",
       "      <td>disappointingli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18410</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>900</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18411</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>414</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18413</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>372</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18409</th>\n",
       "      <td>disappoint</td>\n",
       "      <td>94</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18414</th>\n",
       "      <td>disappointments</td>\n",
       "      <td>31</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415</th>\n",
       "      <td>disappoints</td>\n",
       "      <td>20</td>\n",
       "      <td>disappoint</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  count             stem\n",
       "18412  disappointingly     24  disappointingli\n",
       "18410     disappointed    900       disappoint\n",
       "18411    disappointing    414       disappoint\n",
       "18413   disappointment    372       disappoint\n",
       "18409       disappoint     94       disappoint\n",
       "18414  disappointments     31       disappoint\n",
       "18415      disappoints     20       disappoint"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preprocess.uniqueWords.shape)\n",
    "preprocess.uniqueWords[preprocess.uniqueWords.word.str.contains(\"disappoint\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30714, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>disappoint</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointingli</th>\n",
       "      <td>disappointingly</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            word  count\n",
       "stem                                   \n",
       "disappoint          disappointed    900\n",
       "disappointingli  disappointingly     24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preprocess.uniqueStems.shape)\n",
    "preprocess.uniqueStems[preprocess.uniqueStems.word.str.contains(\"disappoint\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Engineering\n",
    "Next, we take the preprocessed texts as input and calculate their TF-IDF's ([info](http://www.tfidf.com)). We retain 10000 features per text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union([\"thats\",\"weve\",\"dont\",\"lets\",\"youre\",\"im\",\"thi\",\"ha\",\n",
    "    \"wa\",\"st\",\"ask\",\"want\",\"like\",\"thank\",\"know\",\"susan\",\"ryan\",\"say\",\"got\",\"ought\",\"ive\",\"theyre\"])\n",
    "tfidf = TfidfVectorizer(min_df=2, max_features=10000, stop_words=stop_words) #, ngram_range=(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainX = tfidf.fit_transform(trainX).toarray()\n",
    "testX = tfidf.fit_transform(testX).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = reviews_train.label\n",
    "testY =reviews_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000) (25000,)\n",
      "(25000, 10000) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)\n",
    "\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Selection\n",
    "Next, we take the 10k dimensional tfidf's as input, and keep the 2000 dimensions that correlate the most with our sentiment target. The corresponding words - see below - make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01274173 -0.0180222   0.00906162 ...  0.01701741  0.02091131\n",
      "  0.00975959]\n"
     ]
    }
   ],
   "source": [
    "getCorrelation = np.vectorize(lambda x: pearsonr(trainX[:,x], trainY)[0])\n",
    "correlations = getCorrelation(np.arange(trainX.shape[1]))\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIndeces = np.argsort(-correlations)\n",
    "bestIndeces = allIndeces[np.concatenate([np.arange(1000), np.arange(-1000, 0)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grateful' 'loudly' 'evidenced' 'bend' 'bbc' 'perpetrator' 'fascism'\n",
      " 'endeavors' 'amber' 'perplexed']\n",
      "['pope' 'stubborn' 'hoskins' 'words' 'teller' 'bond' 'avery' 'waning'\n",
      " 'work' 'babysitter']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = np.array(tfidf.get_feature_names())\n",
    "print(vocabulary[bestIndeces][:10])\n",
    "print(vocabulary[bestIndeces][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX[:,bestIndeces]\n",
    "testX  = testX [:,bestIndeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2000) (25000,)\n",
      "(25000, 2000) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape,testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Architecture\n",
    "We choose a very simple dense network with 6 layers, performing binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\REVANTH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\REVANTH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "DROPOUT = 0.5\n",
    "ACTIVATION = \"tanh\"\n",
    "\n",
    "model = Sequential([    \n",
    "    Dense(int(trainX.shape[1]/2), activation=ACTIVATION, input_dim=trainX.shape[1]),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(int(trainX.shape[1]/2), activation=ACTIVATION, input_dim=trainX.shape[1]),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(int(trainX.shape[1]/4), activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(100, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(20, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(5, activation=ACTIVATION),\n",
    "    Dropout(DROPOUT),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 3,554,731\n",
      "Trainable params: 3,554,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(0.00005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Training\n",
    "Let's go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCHSIZE = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\REVANTH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 9s 431us/sample - loss: 0.7017 - acc: 0.5051 - val_loss: 0.6827 - val_acc: 0.6708\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 8s 391us/sample - loss: 0.6883 - acc: 0.5362 - val_loss: 0.6702 - val_acc: 0.7636\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 8s 406us/sample - loss: 0.6766 - acc: 0.5651 - val_loss: 0.6546 - val_acc: 0.8032\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 8s 395us/sample - loss: 0.6612 - acc: 0.6087 - val_loss: 0.6333 - val_acc: 0.8232\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 8s 404us/sample - loss: 0.6401 - acc: 0.6452 - val_loss: 0.6040 - val_acc: 0.8306\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 11s 575us/sample - loss: 0.6119 - acc: 0.6877 - val_loss: 0.5663 - val_acc: 0.8394\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 8s 415us/sample - loss: 0.5822 - acc: 0.7240 - val_loss: 0.5238 - val_acc: 0.8470\n",
      "Epoch 8/100\n",
      "20000/20000 [==============================] - 9s 429us/sample - loss: 0.5505 - acc: 0.7620 - val_loss: 0.4824 - val_acc: 0.8514\n",
      "Epoch 9/100\n",
      "20000/20000 [==============================] - 8s 422us/sample - loss: 0.5201 - acc: 0.7908 - val_loss: 0.4474 - val_acc: 0.8582\n",
      "Epoch 10/100\n",
      "20000/20000 [==============================] - 9s 431us/sample - loss: 0.4940 - acc: 0.8102 - val_loss: 0.4190 - val_acc: 0.8610\n",
      "Epoch 11/100\n",
      "20000/20000 [==============================] - 9s 457us/sample - loss: 0.4713 - acc: 0.8267 - val_loss: 0.3973 - val_acc: 0.8664\n",
      "Epoch 12/100\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 0.4559 - acc: 0.8378 - val_loss: 0.3808 - val_acc: 0.8698\n",
      "Epoch 13/100\n",
      "20000/20000 [==============================] - 9s 456us/sample - loss: 0.4416 - acc: 0.8459 - val_loss: 0.3684 - val_acc: 0.8738\n",
      "Epoch 14/100\n",
      "20000/20000 [==============================] - 9s 453us/sample - loss: 0.4297 - acc: 0.8512 - val_loss: 0.3591 - val_acc: 0.8762\n",
      "Epoch 15/100\n",
      "20000/20000 [==============================] - 10s 508us/sample - loss: 0.4187 - acc: 0.8579 - val_loss: 0.3517 - val_acc: 0.8780\n",
      "Epoch 16/100\n",
      "20000/20000 [==============================] - 11s 531us/sample - loss: 0.4119 - acc: 0.8615 - val_loss: 0.3457 - val_acc: 0.8798\n",
      "Epoch 17/100\n",
      "20000/20000 [==============================] - 9s 440us/sample - loss: 0.4061 - acc: 0.8661 - val_loss: 0.3408 - val_acc: 0.8832\n",
      "Epoch 18/100\n",
      "20000/20000 [==============================] - 8s 411us/sample - loss: 0.4017 - acc: 0.8705 - val_loss: 0.3373 - val_acc: 0.8838\n",
      "Epoch 19/100\n",
      "20000/20000 [==============================] - 8s 400us/sample - loss: 0.3930 - acc: 0.8724 - val_loss: 0.3345 - val_acc: 0.8854\n",
      "Epoch 20/100\n",
      "20000/20000 [==============================] - 8s 404us/sample - loss: 0.3916 - acc: 0.8740 - val_loss: 0.3324 - val_acc: 0.8860\n",
      "Epoch 21/100\n",
      "20000/20000 [==============================] - 9s 455us/sample - loss: 0.3891 - acc: 0.8765 - val_loss: 0.3309 - val_acc: 0.8846\n",
      "Epoch 22/100\n",
      "20000/20000 [==============================] - 9s 467us/sample - loss: 0.3844 - acc: 0.8793 - val_loss: 0.3300 - val_acc: 0.8852\n",
      "Epoch 23/100\n",
      "20000/20000 [==============================] - 10s 482us/sample - loss: 0.3819 - acc: 0.8816 - val_loss: 0.3285 - val_acc: 0.8854\n",
      "Epoch 24/100\n",
      "20000/20000 [==============================] - 9s 471us/sample - loss: 0.3725 - acc: 0.8856 - val_loss: 0.3278 - val_acc: 0.8846\n",
      "Epoch 25/100\n",
      "20000/20000 [==============================] - 9s 474us/sample - loss: 0.3761 - acc: 0.8852 - val_loss: 0.3274 - val_acc: 0.8848\n",
      "Epoch 26/100\n",
      "20000/20000 [==============================] - 9s 428us/sample - loss: 0.3680 - acc: 0.8856 - val_loss: 0.3268 - val_acc: 0.8840\n",
      "Epoch 27/100\n",
      "20000/20000 [==============================] - 9s 475us/sample - loss: 0.3701 - acc: 0.8875 - val_loss: 0.3266 - val_acc: 0.8832\n",
      "Epoch 28/100\n",
      "20000/20000 [==============================] - 10s 479us/sample - loss: 0.3686 - acc: 0.8875 - val_loss: 0.3263 - val_acc: 0.8834\n",
      "Epoch 29/100\n",
      "20000/20000 [==============================] - 10s 506us/sample - loss: 0.3628 - acc: 0.8907 - val_loss: 0.3259 - val_acc: 0.8826\n",
      "Epoch 30/100\n",
      "20000/20000 [==============================] - 10s 518us/sample - loss: 0.3607 - acc: 0.8917 - val_loss: 0.3260 - val_acc: 0.8838\n",
      "Epoch 31/100\n",
      "20000/20000 [==============================] - 10s 512us/sample - loss: 0.3599 - acc: 0.8963 - val_loss: 0.3264 - val_acc: 0.8828\n",
      "Epoch 32/100\n",
      "20000/20000 [==============================] - 11s 540us/sample - loss: 0.3564 - acc: 0.8971 - val_loss: 0.3261 - val_acc: 0.8830\n",
      "Epoch 33/100\n",
      "20000/20000 [==============================] - 11s 540us/sample - loss: 0.3587 - acc: 0.8942 - val_loss: 0.3264 - val_acc: 0.8826\n",
      "Epoch 34/100\n",
      "20000/20000 [==============================] - 11s 573us/sample - loss: 0.3607 - acc: 0.8934 - val_loss: 0.3272 - val_acc: 0.8826\n",
      "Epoch 35/100\n",
      "20000/20000 [==============================] - 12s 576us/sample - loss: 0.3513 - acc: 0.8959 - val_loss: 0.3270 - val_acc: 0.8812\n",
      "Epoch 36/100\n",
      "20000/20000 [==============================] - 10s 484us/sample - loss: 0.3513 - acc: 0.8955 - val_loss: 0.3275 - val_acc: 0.8808\n",
      "Epoch 37/100\n",
      "20000/20000 [==============================] - 10s 524us/sample - loss: 0.3552 - acc: 0.8967 - val_loss: 0.3285 - val_acc: 0.8800\n",
      "Epoch 38/100\n",
      "20000/20000 [==============================] - 13s 671us/sample - loss: 0.3493 - acc: 0.8965 - val_loss: 0.3287 - val_acc: 0.8800\n",
      "Epoch 39/100\n",
      "20000/20000 [==============================] - 14s 678us/sample - loss: 0.3491 - acc: 0.8953 - val_loss: 0.3283 - val_acc: 0.8804\n",
      "Epoch 40/100\n",
      "20000/20000 [==============================] - 11s 567us/sample - loss: 0.3479 - acc: 0.8995 - val_loss: 0.3302 - val_acc: 0.8798\n",
      "Epoch 41/100\n",
      "20000/20000 [==============================] - 11s 549us/sample - loss: 0.3493 - acc: 0.8971 - val_loss: 0.3293 - val_acc: 0.8792\n",
      "Epoch 42/100\n",
      "20000/20000 [==============================] - 11s 560us/sample - loss: 0.3446 - acc: 0.9010 - val_loss: 0.3305 - val_acc: 0.8774\n",
      "Epoch 43/100\n",
      "20000/20000 [==============================] - 10s 523us/sample - loss: 0.3431 - acc: 0.8977 - val_loss: 0.3305 - val_acc: 0.8772\n",
      "Epoch 44/100\n",
      "20000/20000 [==============================] - 12s 616us/sample - loss: 0.3440 - acc: 0.9022 - val_loss: 0.3318 - val_acc: 0.8770\n",
      "Epoch 45/100\n",
      "20000/20000 [==============================] - 10s 501us/sample - loss: 0.3399 - acc: 0.9026 - val_loss: 0.3322 - val_acc: 0.8768\n",
      "Epoch 46/100\n",
      "20000/20000 [==============================] - 10s 491us/sample - loss: 0.3402 - acc: 0.9028 - val_loss: 0.3339 - val_acc: 0.8772\n",
      "Epoch 47/100\n",
      "20000/20000 [==============================] - 12s 591us/sample - loss: 0.3378 - acc: 0.9036 - val_loss: 0.3335 - val_acc: 0.8772\n",
      "Epoch 48/100\n",
      "20000/20000 [==============================] - 10s 509us/sample - loss: 0.3386 - acc: 0.9027 - val_loss: 0.3346 - val_acc: 0.8768\n",
      "Epoch 49/100\n",
      "20000/20000 [==============================] - 10s 482us/sample - loss: 0.3409 - acc: 0.9036 - val_loss: 0.3342 - val_acc: 0.8784\n",
      "Epoch 50/100\n",
      "20000/20000 [==============================] - 12s 590us/sample - loss: 0.3389 - acc: 0.9014 - val_loss: 0.3347 - val_acc: 0.8778\n",
      "Epoch 51/100\n",
      "20000/20000 [==============================] - 10s 490us/sample - loss: 0.3348 - acc: 0.9050 - val_loss: 0.3352 - val_acc: 0.8772\n",
      "Epoch 52/100\n",
      "20000/20000 [==============================] - 10s 524us/sample - loss: 0.3369 - acc: 0.9042 - val_loss: 0.3353 - val_acc: 0.8768\n",
      "Epoch 53/100\n",
      "20000/20000 [==============================] - 10s 508us/sample - loss: 0.3392 - acc: 0.9020 - val_loss: 0.3360 - val_acc: 0.8758\n",
      "Epoch 54/100\n",
      "20000/20000 [==============================] - 9s 443us/sample - loss: 0.3285 - acc: 0.9071 - val_loss: 0.3367 - val_acc: 0.8756\n",
      "Epoch 55/100\n",
      "20000/20000 [==============================] - 9s 453us/sample - loss: 0.3334 - acc: 0.9067 - val_loss: 0.3366 - val_acc: 0.8762\n",
      "Epoch 56/100\n",
      "20000/20000 [==============================] - 9s 457us/sample - loss: 0.3318 - acc: 0.9051 - val_loss: 0.3367 - val_acc: 0.8786\n",
      "Epoch 57/100\n",
      "20000/20000 [==============================] - 9s 426us/sample - loss: 0.3321 - acc: 0.9054 - val_loss: 0.3380 - val_acc: 0.8754\n",
      "Epoch 58/100\n",
      "20000/20000 [==============================] - 8s 424us/sample - loss: 0.3341 - acc: 0.9071 - val_loss: 0.3380 - val_acc: 0.8768\n",
      "Epoch 59/100\n",
      "20000/20000 [==============================] - 10s 490us/sample - loss: 0.3295 - acc: 0.9089 - val_loss: 0.3392 - val_acc: 0.8732\n",
      "Epoch 60/100\n",
      "20000/20000 [==============================] - 10s 509us/sample - loss: 0.3281 - acc: 0.9075 - val_loss: 0.3383 - val_acc: 0.8762\n",
      "Epoch 61/100\n",
      "20000/20000 [==============================] - 10s 523us/sample - loss: 0.3288 - acc: 0.9068 - val_loss: 0.3390 - val_acc: 0.8746\n",
      "Epoch 62/100\n",
      "20000/20000 [==============================] - 10s 524us/sample - loss: 0.3308 - acc: 0.9062 - val_loss: 0.3408 - val_acc: 0.8732\n",
      "Epoch 63/100\n",
      "20000/20000 [==============================] - 10s 523us/sample - loss: 0.3306 - acc: 0.9058 - val_loss: 0.3403 - val_acc: 0.8746\n",
      "Epoch 64/100\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 0.3264 - acc: 0.9093 - val_loss: 0.3405 - val_acc: 0.8746\n",
      "Epoch 65/100\n",
      "20000/20000 [==============================] - 10s 504us/sample - loss: 0.3248 - acc: 0.9102 - val_loss: 0.3406 - val_acc: 0.8744\n",
      "Epoch 66/100\n",
      "20000/20000 [==============================] - 11s 526us/sample - loss: 0.3244 - acc: 0.9111 - val_loss: 0.3406 - val_acc: 0.8764\n",
      "Epoch 67/100\n",
      "20000/20000 [==============================] - 11s 532us/sample - loss: 0.3243 - acc: 0.9107 - val_loss: 0.3425 - val_acc: 0.8730\n",
      "Epoch 68/100\n",
      "20000/20000 [==============================] - 11s 528us/sample - loss: 0.3221 - acc: 0.9097 - val_loss: 0.3435 - val_acc: 0.8736\n",
      "Epoch 69/100\n",
      "20000/20000 [==============================] - 11s 530us/sample - loss: 0.3223 - acc: 0.9103 - val_loss: 0.3435 - val_acc: 0.8738\n",
      "Epoch 70/100\n",
      "20000/20000 [==============================] - 10s 480us/sample - loss: 0.3230 - acc: 0.9121 - val_loss: 0.3437 - val_acc: 0.8734\n",
      "Epoch 71/100\n",
      "20000/20000 [==============================] - 10s 499us/sample - loss: 0.3213 - acc: 0.9131 - val_loss: 0.3434 - val_acc: 0.8748\n",
      "Epoch 72/100\n",
      "20000/20000 [==============================] - 11s 567us/sample - loss: 0.3203 - acc: 0.9096 - val_loss: 0.3453 - val_acc: 0.8738\n",
      "Epoch 73/100\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 0.3205 - acc: 0.9121 - val_loss: 0.3461 - val_acc: 0.8734\n",
      "Epoch 74/100\n",
      "20000/20000 [==============================] - 10s 499us/sample - loss: 0.3238 - acc: 0.9104 - val_loss: 0.3471 - val_acc: 0.8730\n",
      "Epoch 75/100\n",
      "20000/20000 [==============================] - 10s 499us/sample - loss: 0.3186 - acc: 0.9115 - val_loss: 0.3462 - val_acc: 0.8750\n",
      "Epoch 76/100\n",
      "20000/20000 [==============================] - 10s 483us/sample - loss: 0.3178 - acc: 0.9130 - val_loss: 0.3483 - val_acc: 0.8716\n",
      "Epoch 77/100\n",
      "20000/20000 [==============================] - 10s 488us/sample - loss: 0.3181 - acc: 0.9136 - val_loss: 0.3470 - val_acc: 0.8728\n",
      "Epoch 78/100\n",
      "20000/20000 [==============================] - 10s 522us/sample - loss: 0.3162 - acc: 0.9131 - val_loss: 0.3461 - val_acc: 0.8752\n",
      "Epoch 79/100\n",
      "20000/20000 [==============================] - 11s 530us/sample - loss: 0.3160 - acc: 0.9147 - val_loss: 0.3465 - val_acc: 0.8738\n",
      "Epoch 80/100\n",
      "20000/20000 [==============================] - 10s 488us/sample - loss: 0.3208 - acc: 0.9115 - val_loss: 0.3465 - val_acc: 0.8736\n",
      "Epoch 81/100\n",
      "20000/20000 [==============================] - 10s 503us/sample - loss: 0.3155 - acc: 0.9126 - val_loss: 0.3490 - val_acc: 0.8718\n",
      "Epoch 82/100\n",
      "20000/20000 [==============================] - 9s 457us/sample - loss: 0.3214 - acc: 0.9121 - val_loss: 0.3489 - val_acc: 0.8714\n",
      "Epoch 83/100\n",
      "20000/20000 [==============================] - 10s 523us/sample - loss: 0.3139 - acc: 0.9137 - val_loss: 0.3499 - val_acc: 0.8714\n",
      "Epoch 84/100\n",
      "20000/20000 [==============================] - 10s 487us/sample - loss: 0.3141 - acc: 0.9135 - val_loss: 0.3500 - val_acc: 0.8708\n",
      "Epoch 85/100\n",
      "20000/20000 [==============================] - 9s 463us/sample - loss: 0.3167 - acc: 0.9143 - val_loss: 0.3514 - val_acc: 0.8712\n",
      "Epoch 86/100\n",
      "20000/20000 [==============================] - 10s 488us/sample - loss: 0.3132 - acc: 0.9151 - val_loss: 0.3502 - val_acc: 0.8722\n",
      "Epoch 87/100\n",
      "20000/20000 [==============================] - 9s 442us/sample - loss: 0.3143 - acc: 0.9151 - val_loss: 0.3527 - val_acc: 0.8706\n",
      "Epoch 88/100\n",
      "20000/20000 [==============================] - 10s 477us/sample - loss: 0.3131 - acc: 0.9140 - val_loss: 0.3525 - val_acc: 0.8704\n",
      "Epoch 89/100\n",
      "20000/20000 [==============================] - 11s 540us/sample - loss: 0.3163 - acc: 0.9115 - val_loss: 0.3534 - val_acc: 0.8700\n",
      "Epoch 90/100\n",
      "20000/20000 [==============================] - 10s 522us/sample - loss: 0.3099 - acc: 0.9154 - val_loss: 0.3537 - val_acc: 0.8706\n",
      "Epoch 91/100\n",
      "20000/20000 [==============================] - 10s 509us/sample - loss: 0.3096 - acc: 0.9161 - val_loss: 0.3534 - val_acc: 0.8716\n",
      "Epoch 92/100\n",
      "20000/20000 [==============================] - 10s 517us/sample - loss: 0.3055 - acc: 0.9176 - val_loss: 0.3536 - val_acc: 0.8708\n",
      "Epoch 93/100\n",
      "20000/20000 [==============================] - 10s 516us/sample - loss: 0.3071 - acc: 0.9172 - val_loss: 0.3526 - val_acc: 0.8718\n",
      "Epoch 94/100\n",
      "20000/20000 [==============================] - 11s 550us/sample - loss: 0.3100 - acc: 0.9182 - val_loss: 0.3531 - val_acc: 0.8716\n",
      "Epoch 95/100\n",
      "20000/20000 [==============================] - 10s 478us/sample - loss: 0.3092 - acc: 0.9151 - val_loss: 0.3546 - val_acc: 0.8702\n",
      "Epoch 96/100\n",
      "20000/20000 [==============================] - 10s 486us/sample - loss: 0.3075 - acc: 0.9165 - val_loss: 0.3541 - val_acc: 0.8694\n",
      "Epoch 97/100\n",
      "20000/20000 [==============================] - 10s 510us/sample - loss: 0.3099 - acc: 0.9163 - val_loss: 0.3532 - val_acc: 0.8714\n",
      "Epoch 98/100\n",
      "20000/20000 [==============================] - 11s 535us/sample - loss: 0.3068 - acc: 0.9153 - val_loss: 0.3540 - val_acc: 0.8722\n",
      "Epoch 99/100\n",
      "20000/20000 [==============================] - 10s 485us/sample - loss: 0.3064 - acc: 0.9171 - val_loss: 0.3533 - val_acc: 0.8728\n",
      "Epoch 100/100\n",
      "20000/20000 [==============================] - 10s 479us/sample - loss: 0.3060 - acc: 0.9175 - val_loss: 0.3544 - val_acc: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25cdb5fb1d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=EPOCHS, batch_size=BATCHSIZE, validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "size": 5
         },
         "name": "Train Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.5051000118255615,
          0.5362499952316284,
          0.5650500059127808,
          0.6086500287055969,
          0.6451500058174133,
          0.6876500248908997,
          0.7239999771118164,
          0.7620000243186951,
          0.7907500267028809,
          0.8102499842643738,
          0.82669997215271,
          0.8378000259399414,
          0.8458999991416931,
          0.8512499928474426,
          0.8578500151634216,
          0.8614500164985657,
          0.866100013256073,
          0.8705499768257141,
          0.8723999857902527,
          0.8740000128746033,
          0.8764500021934509,
          0.8792999982833862,
          0.8816499710083008,
          0.8855500221252441,
          0.885200023651123,
          0.8856499791145325,
          0.887499988079071,
          0.887499988079071,
          0.8906999826431274,
          0.8916500210762024,
          0.8963000178337097,
          0.8970500230789185,
          0.8941500186920166,
          0.8933500051498413,
          0.8958500027656555,
          0.8955000042915344,
          0.8967499732971191,
          0.8964999914169312,
          0.8953499794006348,
          0.8994500041007996,
          0.8970999717712402,
          0.9010499715805054,
          0.8976500034332275,
          0.9021999835968018,
          0.9025999903678894,
          0.9028000235557556,
          0.9035500288009644,
          0.9027000069618225,
          0.9035500288009644,
          0.9013500213623047,
          0.9049500226974487,
          0.9041500091552734,
          0.9019500017166138,
          0.9071000218391418,
          0.9067000150680542,
          0.9050999879837036,
          0.9053500294685364,
          0.9070500135421753,
          0.9088500142097473,
          0.9075499773025513,
          0.9067999720573425,
          0.90625,
          0.9058499932289124,
          0.9093000292778015,
          0.9101999998092651,
          0.911050021648407,
          0.9107000231742859,
          0.9096500277519226,
          0.9103000164031982,
          0.9120500087738037,
          0.913100004196167,
          0.909600019454956,
          0.9120500087738037,
          0.9103999733924866,
          0.911549985408783,
          0.9129999876022339,
          0.9136000275611877,
          0.913100004196167,
          0.9146999716758728,
          0.9114500284194946,
          0.9125999808311462,
          0.9120500087738037,
          0.9137499928474426,
          0.9135000109672546,
          0.9143000245094299,
          0.9150999784469604,
          0.9150500297546387,
          0.9140499830245972,
          0.9114999771118164,
          0.9153500199317932,
          0.9161499738693237,
          0.9175500273704529,
          0.9172000288963318,
          0.918150007724762,
          0.9150999784469604,
          0.916450023651123,
          0.9162999987602234,
          0.9152500033378601,
          0.9170500040054321,
          0.9175000190734863
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Valid Accuracy",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.670799970626831,
          0.7635999917984009,
          0.8032000064849854,
          0.823199987411499,
          0.8306000232696533,
          0.8393999934196472,
          0.847000002861023,
          0.8514000177383423,
          0.8582000136375427,
          0.8610000014305115,
          0.8664000034332275,
          0.8697999715805054,
          0.8737999796867371,
          0.8762000203132629,
          0.878000020980835,
          0.879800021648407,
          0.8831999897956848,
          0.8838000297546387,
          0.8853999972343445,
          0.8859999775886536,
          0.8845999836921692,
          0.885200023651123,
          0.8853999972343445,
          0.8845999836921692,
          0.8848000168800354,
          0.8840000033378601,
          0.8831999897956848,
          0.883400022983551,
          0.8826000094413757,
          0.8838000297546387,
          0.8827999830245972,
          0.8830000162124634,
          0.8826000094413757,
          0.8826000094413757,
          0.8812000155448914,
          0.8808000087738037,
          0.8799999952316284,
          0.8799999952316284,
          0.8804000020027161,
          0.879800021648407,
          0.8791999816894531,
          0.8773999810218811,
          0.8772000074386597,
          0.8769999742507935,
          0.876800000667572,
          0.8772000074386597,
          0.8772000074386597,
          0.876800000667572,
          0.8784000277519226,
          0.8777999877929688,
          0.8772000074386597,
          0.876800000667572,
          0.8758000135421753,
          0.8755999803543091,
          0.8762000203132629,
          0.878600001335144,
          0.8754000067710876,
          0.876800000667572,
          0.873199999332428,
          0.8762000203132629,
          0.8745999932289124,
          0.873199999332428,
          0.8745999932289124,
          0.8745999932289124,
          0.8744000196456909,
          0.8763999938964844,
          0.8730000257492065,
          0.8736000061035156,
          0.8737999796867371,
          0.8733999729156494,
          0.8748000264167786,
          0.8737999796867371,
          0.8733999729156494,
          0.8730000257492065,
          0.875,
          0.8715999722480774,
          0.8727999925613403,
          0.8751999735832214,
          0.8737999796867371,
          0.8736000061035156,
          0.8718000054359436,
          0.871399998664856,
          0.871399998664856,
          0.8708000183105469,
          0.8712000250816345,
          0.8722000122070312,
          0.8705999851226807,
          0.8704000115394592,
          0.8700000047683716,
          0.8705999851226807,
          0.8715999722480774,
          0.8708000183105469,
          0.8718000054359436,
          0.8715999722480774,
          0.870199978351593,
          0.8694000244140625,
          0.871399998664856,
          0.8722000122070312,
          0.8727999925613403,
          0.8722000122070312
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.701687927544117,
          0.688317035138607,
          0.676601167023182,
          0.6612306624650955,
          0.6400616243481636,
          0.6119197502732276,
          0.5822311967611313,
          0.550478671491146,
          0.5201311409473419,
          0.49395824745297434,
          0.471312640607357,
          0.45589217245578767,
          0.4415754400193691,
          0.4296654723584652,
          0.41868741884827615,
          0.4118532225489616,
          0.40612534880638124,
          0.40173264145851134,
          0.39296676218509674,
          0.39155035093426704,
          0.3890730321407318,
          0.3843985661864281,
          0.381901752948761,
          0.37249461710453036,
          0.37606207728385926,
          0.36797219067811965,
          0.3700831674039364,
          0.36862688660621645,
          0.3627695344388485,
          0.36070927456021307,
          0.3599007911980152,
          0.35639831721782683,
          0.3587328054010868,
          0.36065813302993777,
          0.3513226851820946,
          0.35125976949930193,
          0.3552091933786869,
          0.349266067892313,
          0.34910580068826674,
          0.34793980047106743,
          0.3493300169706345,
          0.34459449648857116,
          0.3431468389928341,
          0.3440405040979385,
          0.3398684047162533,
          0.34018990471959115,
          0.33779176473617556,
          0.33860370218753816,
          0.34094716385006907,
          0.33894301429390905,
          0.3348171226680279,
          0.3368722483515739,
          0.3392265848815441,
          0.3285279728472233,
          0.3334437794983387,
          0.33178910315036775,
          0.3320924773812294,
          0.3341096043586731,
          0.32951201424002646,
          0.3280635796487331,
          0.32877723798155783,
          0.33077345639467237,
          0.33057805970311166,
          0.32641093581914904,
          0.32479533553123474,
          0.32442902997136114,
          0.3242793567478657,
          0.3221013881266117,
          0.32233890146017075,
          0.32298180013895034,
          0.3213400073349476,
          0.32033548280596735,
          0.3204613789916039,
          0.3237930990755558,
          0.3185527868568897,
          0.3178192161023617,
          0.3180526152253151,
          0.3161707617342472,
          0.315998849272728,
          0.3207798719406128,
          0.3154502049088478,
          0.3214020565152168,
          0.31387209296226504,
          0.314141308516264,
          0.3166690729558468,
          0.3131993740797043,
          0.3142877914011478,
          0.31311381682753564,
          0.31625937670469284,
          0.30993020012974737,
          0.30960777699947356,
          0.3054795913398266,
          0.30712799578905103,
          0.3100034363567829,
          0.30919667035341264,
          0.30750217363238336,
          0.3098607212305069,
          0.30676032081246374,
          0.30641971826553344,
          0.3060028269886971
         ]
        },
        {
         "marker": {
          "size": 5
         },
         "name": "Valid Loss",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.6827292442321777,
          0.6702431559562683,
          0.654571121931076,
          0.6332512974739075,
          0.603991836309433,
          0.5663228750228881,
          0.5238263010978699,
          0.48243253827095034,
          0.44737653732299804,
          0.41900965571403503,
          0.3973100811243057,
          0.38082176446914673,
          0.36835060715675355,
          0.3590556412935257,
          0.3517220288515091,
          0.3457120507955551,
          0.34080708026885986,
          0.3373109191656113,
          0.3344583630561829,
          0.33241936266422273,
          0.33088426291942596,
          0.3299977868795395,
          0.32853215336799624,
          0.32777313590049745,
          0.3274118065834045,
          0.3267572849988937,
          0.32661919593811034,
          0.3262893706560135,
          0.3259169489145279,
          0.32602780759334565,
          0.32637844383716585,
          0.32611105740070345,
          0.32644452452659606,
          0.32721024453639985,
          0.3270073294639587,
          0.32748613357543943,
          0.3284625142812729,
          0.32866988480091097,
          0.3282971054315567,
          0.3301822155714035,
          0.32925214767456057,
          0.3304672360420227,
          0.3305306911468506,
          0.3317680537700653,
          0.33218233585357665,
          0.33387501537799835,
          0.33354684710502625,
          0.33455590903759,
          0.33415229618549347,
          0.33465545177459716,
          0.33516577184200286,
          0.3353213548660278,
          0.3360293090343475,
          0.33671203851699827,
          0.33656672239303587,
          0.33674881756305697,
          0.33801118433475497,
          0.33797292709350585,
          0.33916168212890624,
          0.3382882386445999,
          0.33902745246887206,
          0.3407592296600342,
          0.3403103470802307,
          0.3405052959918976,
          0.34064984917640684,
          0.3406235367059708,
          0.3425024598836899,
          0.3435384720563889,
          0.34347781240940095,
          0.34373036921024325,
          0.3434350937604904,
          0.3453042596578598,
          0.3460700988769531,
          0.34713112115859984,
          0.34618992507457735,
          0.34825338125228883,
          0.34698345959186555,
          0.3461282342672348,
          0.34649781286716463,
          0.3465003252029419,
          0.3489712715148926,
          0.3488625228404999,
          0.34990879595279695,
          0.3500208556652069,
          0.35136722922325136,
          0.350243067741394,
          0.3526632100343704,
          0.3525089204311371,
          0.3533600062131882,
          0.3536647856235504,
          0.3533899158239365,
          0.35355002284049986,
          0.35257368087768554,
          0.35313362777233126,
          0.35457024574279783,
          0.35406236350536346,
          0.3532315194606781,
          0.3540112555027008,
          0.35332060754299166,
          0.35440485179424286
         ]
        }
       ],
       "layout": {
        "font": {
         "family": "Palatino"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Model Training Evolution"
        },
        "xaxis": {
         "dtick": 1,
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"dace736a-d477-4de1-bb27-72d1dcddd628\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"dace736a-d477-4de1-bb27-72d1dcddd628\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'dace736a-d477-4de1-bb27-72d1dcddd628',\n",
       "                        [{\"marker\": {\"size\": 5}, \"name\": \"Train Accuracy\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.5051000118255615, 0.5362499952316284, 0.5650500059127808, 0.6086500287055969, 0.6451500058174133, 0.6876500248908997, 0.7239999771118164, 0.7620000243186951, 0.7907500267028809, 0.8102499842643738, 0.82669997215271, 0.8378000259399414, 0.8458999991416931, 0.8512499928474426, 0.8578500151634216, 0.8614500164985657, 0.866100013256073, 0.8705499768257141, 0.8723999857902527, 0.8740000128746033, 0.8764500021934509, 0.8792999982833862, 0.8816499710083008, 0.8855500221252441, 0.885200023651123, 0.8856499791145325, 0.887499988079071, 0.887499988079071, 0.8906999826431274, 0.8916500210762024, 0.8963000178337097, 0.8970500230789185, 0.8941500186920166, 0.8933500051498413, 0.8958500027656555, 0.8955000042915344, 0.8967499732971191, 0.8964999914169312, 0.8953499794006348, 0.8994500041007996, 0.8970999717712402, 0.9010499715805054, 0.8976500034332275, 0.9021999835968018, 0.9025999903678894, 0.9028000235557556, 0.9035500288009644, 0.9027000069618225, 0.9035500288009644, 0.9013500213623047, 0.9049500226974487, 0.9041500091552734, 0.9019500017166138, 0.9071000218391418, 0.9067000150680542, 0.9050999879837036, 0.9053500294685364, 0.9070500135421753, 0.9088500142097473, 0.9075499773025513, 0.9067999720573425, 0.90625, 0.9058499932289124, 0.9093000292778015, 0.9101999998092651, 0.911050021648407, 0.9107000231742859, 0.9096500277519226, 0.9103000164031982, 0.9120500087738037, 0.913100004196167, 0.909600019454956, 0.9120500087738037, 0.9103999733924866, 0.911549985408783, 0.9129999876022339, 0.9136000275611877, 0.913100004196167, 0.9146999716758728, 0.9114500284194946, 0.9125999808311462, 0.9120500087738037, 0.9137499928474426, 0.9135000109672546, 0.9143000245094299, 0.9150999784469604, 0.9150500297546387, 0.9140499830245972, 0.9114999771118164, 0.9153500199317932, 0.9161499738693237, 0.9175500273704529, 0.9172000288963318, 0.918150007724762, 0.9150999784469604, 0.916450023651123, 0.9162999987602234, 0.9152500033378601, 0.9170500040054321, 0.9175000190734863], \"yaxis\": \"y2\"}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Accuracy\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.670799970626831, 0.7635999917984009, 0.8032000064849854, 0.823199987411499, 0.8306000232696533, 0.8393999934196472, 0.847000002861023, 0.8514000177383423, 0.8582000136375427, 0.8610000014305115, 0.8664000034332275, 0.8697999715805054, 0.8737999796867371, 0.8762000203132629, 0.878000020980835, 0.879800021648407, 0.8831999897956848, 0.8838000297546387, 0.8853999972343445, 0.8859999775886536, 0.8845999836921692, 0.885200023651123, 0.8853999972343445, 0.8845999836921692, 0.8848000168800354, 0.8840000033378601, 0.8831999897956848, 0.883400022983551, 0.8826000094413757, 0.8838000297546387, 0.8827999830245972, 0.8830000162124634, 0.8826000094413757, 0.8826000094413757, 0.8812000155448914, 0.8808000087738037, 0.8799999952316284, 0.8799999952316284, 0.8804000020027161, 0.879800021648407, 0.8791999816894531, 0.8773999810218811, 0.8772000074386597, 0.8769999742507935, 0.876800000667572, 0.8772000074386597, 0.8772000074386597, 0.876800000667572, 0.8784000277519226, 0.8777999877929688, 0.8772000074386597, 0.876800000667572, 0.8758000135421753, 0.8755999803543091, 0.8762000203132629, 0.878600001335144, 0.8754000067710876, 0.876800000667572, 0.873199999332428, 0.8762000203132629, 0.8745999932289124, 0.873199999332428, 0.8745999932289124, 0.8745999932289124, 0.8744000196456909, 0.8763999938964844, 0.8730000257492065, 0.8736000061035156, 0.8737999796867371, 0.8733999729156494, 0.8748000264167786, 0.8737999796867371, 0.8733999729156494, 0.8730000257492065, 0.875, 0.8715999722480774, 0.8727999925613403, 0.8751999735832214, 0.8737999796867371, 0.8736000061035156, 0.8718000054359436, 0.871399998664856, 0.871399998664856, 0.8708000183105469, 0.8712000250816345, 0.8722000122070312, 0.8705999851226807, 0.8704000115394592, 0.8700000047683716, 0.8705999851226807, 0.8715999722480774, 0.8708000183105469, 0.8718000054359436, 0.8715999722480774, 0.870199978351593, 0.8694000244140625, 0.871399998664856, 0.8722000122070312, 0.8727999925613403, 0.8722000122070312], \"yaxis\": \"y2\"}, {\"marker\": {\"size\": 5}, \"name\": \"Train Loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.701687927544117, 0.688317035138607, 0.676601167023182, 0.6612306624650955, 0.6400616243481636, 0.6119197502732276, 0.5822311967611313, 0.550478671491146, 0.5201311409473419, 0.49395824745297434, 0.471312640607357, 0.45589217245578767, 0.4415754400193691, 0.4296654723584652, 0.41868741884827615, 0.4118532225489616, 0.40612534880638124, 0.40173264145851134, 0.39296676218509674, 0.39155035093426704, 0.3890730321407318, 0.3843985661864281, 0.381901752948761, 0.37249461710453036, 0.37606207728385926, 0.36797219067811965, 0.3700831674039364, 0.36862688660621645, 0.3627695344388485, 0.36070927456021307, 0.3599007911980152, 0.35639831721782683, 0.3587328054010868, 0.36065813302993777, 0.3513226851820946, 0.35125976949930193, 0.3552091933786869, 0.349266067892313, 0.34910580068826674, 0.34793980047106743, 0.3493300169706345, 0.34459449648857116, 0.3431468389928341, 0.3440405040979385, 0.3398684047162533, 0.34018990471959115, 0.33779176473617556, 0.33860370218753816, 0.34094716385006907, 0.33894301429390905, 0.3348171226680279, 0.3368722483515739, 0.3392265848815441, 0.3285279728472233, 0.3334437794983387, 0.33178910315036775, 0.3320924773812294, 0.3341096043586731, 0.32951201424002646, 0.3280635796487331, 0.32877723798155783, 0.33077345639467237, 0.33057805970311166, 0.32641093581914904, 0.32479533553123474, 0.32442902997136114, 0.3242793567478657, 0.3221013881266117, 0.32233890146017075, 0.32298180013895034, 0.3213400073349476, 0.32033548280596735, 0.3204613789916039, 0.3237930990755558, 0.3185527868568897, 0.3178192161023617, 0.3180526152253151, 0.3161707617342472, 0.315998849272728, 0.3207798719406128, 0.3154502049088478, 0.3214020565152168, 0.31387209296226504, 0.314141308516264, 0.3166690729558468, 0.3131993740797043, 0.3142877914011478, 0.31311381682753564, 0.31625937670469284, 0.30993020012974737, 0.30960777699947356, 0.3054795913398266, 0.30712799578905103, 0.3100034363567829, 0.30919667035341264, 0.30750217363238336, 0.3098607212305069, 0.30676032081246374, 0.30641971826553344, 0.3060028269886971]}, {\"marker\": {\"size\": 5}, \"name\": \"Valid Loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [0.6827292442321777, 0.6702431559562683, 0.654571121931076, 0.6332512974739075, 0.603991836309433, 0.5663228750228881, 0.5238263010978699, 0.48243253827095034, 0.44737653732299804, 0.41900965571403503, 0.3973100811243057, 0.38082176446914673, 0.36835060715675355, 0.3590556412935257, 0.3517220288515091, 0.3457120507955551, 0.34080708026885986, 0.3373109191656113, 0.3344583630561829, 0.33241936266422273, 0.33088426291942596, 0.3299977868795395, 0.32853215336799624, 0.32777313590049745, 0.3274118065834045, 0.3267572849988937, 0.32661919593811034, 0.3262893706560135, 0.3259169489145279, 0.32602780759334565, 0.32637844383716585, 0.32611105740070345, 0.32644452452659606, 0.32721024453639985, 0.3270073294639587, 0.32748613357543943, 0.3284625142812729, 0.32866988480091097, 0.3282971054315567, 0.3301822155714035, 0.32925214767456057, 0.3304672360420227, 0.3305306911468506, 0.3317680537700653, 0.33218233585357665, 0.33387501537799835, 0.33354684710502625, 0.33455590903759, 0.33415229618549347, 0.33465545177459716, 0.33516577184200286, 0.3353213548660278, 0.3360293090343475, 0.33671203851699827, 0.33656672239303587, 0.33674881756305697, 0.33801118433475497, 0.33797292709350585, 0.33916168212890624, 0.3382882386445999, 0.33902745246887206, 0.3407592296600342, 0.3403103470802307, 0.3405052959918976, 0.34064984917640684, 0.3406235367059708, 0.3425024598836899, 0.3435384720563889, 0.34347781240940095, 0.34373036921024325, 0.3434350937604904, 0.3453042596578598, 0.3460700988769531, 0.34713112115859984, 0.34618992507457735, 0.34825338125228883, 0.34698345959186555, 0.3461282342672348, 0.34649781286716463, 0.3465003252029419, 0.3489712715148926, 0.3488625228404999, 0.34990879595279695, 0.3500208556652069, 0.35136722922325136, 0.350243067741394, 0.3526632100343704, 0.3525089204311371, 0.3533600062131882, 0.3536647856235504, 0.3533899158239365, 0.35355002284049986, 0.35257368087768554, 0.35313362777233126, 0.35457024574279783, 0.35406236350536346, 0.3532315194606781, 0.3540112555027008, 0.35332060754299166, 0.35440485179424286]}],\n",
       "                        {\"font\": {\"family\": \"Palatino\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Model Training Evolution\"}, \"xaxis\": {\"dtick\": 1, \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"domain\": [0, 0.45], \"title\": {\"text\": \"Loss\"}}, \"yaxis2\": {\"domain\": [0.55, 1], \"title\": {\"text\": \"Accuracy\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('dace736a-d477-4de1-bb27-72d1dcddd628');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(EPOCHS)\n",
    "history = model.history.history\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=x, y=history[\"acc\"], name=\"Train Accuracy\", marker=dict(size=5), yaxis='y2'),\n",
    "    go.Scatter(x=x, y=history[\"val_acc\"], name=\"Valid Accuracy\", marker=dict(size=5), yaxis='y2'),\n",
    "    go.Scatter(x=x, y=history[\"loss\"], name=\"Train Loss\", marker=dict(size=5)),\n",
    "    go.Scatter(x=x, y=history[\"val_loss\"], name=\"Valid Loss\", marker=dict(size=5))\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title=\"Model Training Evolution\", font=dict(family='Palatino'), xaxis=dict(title='Epoch', dtick=1),\n",
    "    yaxis1=dict(title=\"Loss\", domain=[0, 0.45]), yaxis2=dict(title=\"Accuracy\", domain=[0.55, 1]),\n",
    ")\n",
    "py.iplot(go.Figure(data=data, layout=layout), show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "### Accuracy & Loss\n",
    "Let's first centralize the probabilities and predictions with the original train and validation dataframes. Then we can print out the respective accuracies and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>Diane Keaton gave an outstanding performance i...</td>\n",
       "      <td>1</td>\n",
       "      <td>8610_10.txt</td>\n",
       "      <td>0.895504</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>This has to be creepiest, most twisted holiday...</td>\n",
       "      <td>0</td>\n",
       "      <td>3060_1.txt</td>\n",
       "      <td>0.094351</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Do not expect a depiction of the \"truth\". Howe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3423_7.txt</td>\n",
       "      <td>0.903977</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>The League of Gentlemen is one of the funniest...</td>\n",
       "      <td>1</td>\n",
       "      <td>9706_10.txt</td>\n",
       "      <td>0.903593</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Narratives  whether written, visual or poeti...</td>\n",
       "      <td>1</td>\n",
       "      <td>10211_7.txt</td>\n",
       "      <td>0.903887</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "10955  Diane Keaton gave an outstanding performance i...      1  8610_10.txt   \n",
       "17289  This has to be creepiest, most twisted holiday...      0   3060_1.txt   \n",
       "5192   Do not expect a depiction of the \"truth\". Howe...      1   3423_7.txt   \n",
       "12172  The League of Gentlemen is one of the funniest...      1  9706_10.txt   \n",
       "235    Narratives  whether written, visual or poeti...      1  10211_7.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "10955     0.895504        True   True  \n",
       "17289     0.094351       False  False  \n",
       "5192      0.903977        True   True  \n",
       "12172     0.903593        True   True  \n",
       "235       0.903887        True   True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train[\"probability\"] = model.predict(trainX)\n",
    "reviews_train[\"prediction\"] = reviews_train.probability-0.5>0\n",
    "reviews_train[\"truth\"] = reviews_train.label==1\n",
    "reviews_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 331us/sample - loss: 0.2440 - acc: 0.9301\n",
      "[0.24397008286714553, 0.93012]\n",
      "0.93012\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(trainX, trainY))\n",
    "print((reviews_train.truth==reviews_train.prediction).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>This movie is a fascinating drama about the Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>8610_8.txt</td>\n",
       "      <td>0.094942</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>It's too kind to call this a \"fictionalized\" a...</td>\n",
       "      <td>0</td>\n",
       "      <td>3060_3.txt</td>\n",
       "      <td>0.096035</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>I was unsure of this movie before renting and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3423_9.txt</td>\n",
       "      <td>0.904331</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>Just got out of an advance screening, and wow ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9706_7.txt</td>\n",
       "      <td>0.164973</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>I doubt if the real story of the development o...</td>\n",
       "      <td>1</td>\n",
       "      <td>10211_8.txt</td>\n",
       "      <td>0.094346</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "10955  This movie is a fascinating drama about the Ma...      1   8610_8.txt   \n",
       "17289  It's too kind to call this a \"fictionalized\" a...      0   3060_3.txt   \n",
       "5192   I was unsure of this movie before renting and ...      1   3423_9.txt   \n",
       "12172  Just got out of an advance screening, and wow ...      1   9706_7.txt   \n",
       "235    I doubt if the real story of the development o...      1  10211_8.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "10955     0.094942       False   True  \n",
       "17289     0.096035       False  False  \n",
       "5192      0.904331        True   True  \n",
       "12172     0.164973       False   True  \n",
       "235       0.094346       False   True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test[\"probability\"] = model.predict(testX)4\n",
    "reviews_test[\"prediction\"] = reviews_test.probability-0.5>0\n",
    "reviews_test[\"truth\"] = reviews_test.label==1\n",
    "reviews_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 320us/sample - loss: 1.1098 - acc: 0.4962\n",
      "[1.1097714756011963, 0.4962]\n",
      "0.4962\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(testX, testY))\n",
    "print((reviews_test.truth==reviews_test.prediction).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "Error analysis gives us great insight in the way the model is making its errors. Often, it shows data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>11567</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>933</td>\n",
       "      <td>11686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "prediction              \n",
       "False       11567    814\n",
       "True          933  11686"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCross = reviews_train.groupby([\"prediction\", \"truth\"]).size().unstack()\n",
    "trainCross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>truth</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7551</td>\n",
       "      <td>7646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4949</td>\n",
       "      <td>4854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "truth       False  True \n",
       "prediction              \n",
       "False        7551   7646\n",
       "True         4949   4854"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validCross = reviews_test.groupby([\"prediction\", \"truth\"]).size().unstack()\n",
    "validCross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4854 true positives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>I admit that I almost gave up on watching TV s...</td>\n",
       "      <td>1</td>\n",
       "      <td>5830_10.txt</td>\n",
       "      <td>0.904430</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>A very insightful psychological thriller! Foot...</td>\n",
       "      <td>1</td>\n",
       "      <td>6425_9.txt</td>\n",
       "      <td>0.904416</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>\"Pearl Harbor, buddy.\" This movie is brilliant...</td>\n",
       "      <td>1</td>\n",
       "      <td>3761_8.txt</td>\n",
       "      <td>0.904412</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  label         file  \\\n",
       "7866  I admit that I almost gave up on watching TV s...      1  5830_10.txt   \n",
       "8527  A very insightful psychological thriller! Foot...      1   6425_9.txt   \n",
       "5567  \"Pearl Harbor, buddy.\" This movie is brilliant...      1   3761_8.txt   \n",
       "\n",
       "      probability  prediction  truth  \n",
       "7866     0.904430        True   True  \n",
       "8527     0.904416        True   True  \n",
       "5567     0.904412        True   True  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truepositives = reviews_test[(reviews_test.truth==True)&(reviews_test.truth==reviews_test.prediction)]\n",
    "print(len(truepositives), \"true positives.\")\n",
    "truepositives.sort_values(\"probability\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7551 true negatives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22221</th>\n",
       "      <td>Talented screenwriter Alvin Sargent sadly cann...</td>\n",
       "      <td>0</td>\n",
       "      <td>74_4.txt</td>\n",
       "      <td>0.094289</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23544</th>\n",
       "      <td>Does anyone care about any of the characters i...</td>\n",
       "      <td>0</td>\n",
       "      <td>8691_1.txt</td>\n",
       "      <td>0.094292</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24709</th>\n",
       "      <td>The movie is not as funny as the director's pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>973_4.txt</td>\n",
       "      <td>0.094298</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label        file  \\\n",
       "22221  Talented screenwriter Alvin Sargent sadly cann...      0    74_4.txt   \n",
       "23544  Does anyone care about any of the characters i...      0  8691_1.txt   \n",
       "24709  The movie is not as funny as the director's pr...      0   973_4.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "22221     0.094289       False  False  \n",
       "23544     0.094292       False  False  \n",
       "24709     0.094298       False  False  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truenegatives = reviews_test[(reviews_test.truth==False)&(reviews_test.truth==reviews_test.prediction)]\n",
    "print(len(truenegatives), \"true negatives.\")\n",
    "truenegatives.sort_values(\"probability\", ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7646 false positives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10857</th>\n",
       "      <td>You don't review James Bond movies, you evalua...</td>\n",
       "      <td>1</td>\n",
       "      <td>8522_8.txt</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>In 1983 two Bond movies was made, one was the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8523_10.txt</td>\n",
       "      <td>0.094290</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>Not a film of entertainment, but of real lives...</td>\n",
       "      <td>1</td>\n",
       "      <td>1545_7.txt</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "10857  You don't review James Bond movies, you evalua...      1   8522_8.txt   \n",
       "10858  In 1983 two Bond movies was made, one was the ...      1  8523_10.txt   \n",
       "3105   Not a film of entertainment, but of real lives...      1   1545_7.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "10857     0.094290       False   True  \n",
       "10858     0.094290       False   True  \n",
       "3105      0.094291       False   True  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsepositives = reviews_test[(reviews_test.truth==True)&(reviews_test.truth!=reviews_test.prediction)]\n",
    "print(len(falsepositives), \"false positives.\")\n",
    "falsepositives.sort_values(\"probability\", ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4949 false negatives.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>I sat (uncomfortably) through this film becomi...</td>\n",
       "      <td>0</td>\n",
       "      <td>12203_2.txt</td>\n",
       "      <td>0.904428</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19084</th>\n",
       "      <td>File this one in the `How do movies like this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4677_4.txt</td>\n",
       "      <td>0.904428</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>Here is a rundown of a typical Rachael Ray Sho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1031_1.txt</td>\n",
       "      <td>0.904425</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label         file  \\\n",
       "14948  I sat (uncomfortably) through this film becomi...      0  12203_2.txt   \n",
       "19084  File this one in the `How do movies like this ...      0   4677_4.txt   \n",
       "12855  Here is a rundown of a typical Rachael Ray Sho...      0   1031_1.txt   \n",
       "\n",
       "       probability  prediction  truth  \n",
       "14948     0.904428        True  False  \n",
       "19084     0.904428        True  False  \n",
       "12855     0.904425        True  False  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falsenegatives = reviews_test[(reviews_test.truth==False)&(reviews_test.truth!=reviews_test.prediction)]\n",
    "print(len(falsenegatives), \"false negatives.\")\n",
    "falsenegatives.sort_values(\"probability\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the review that got predicted as positive most certainly - while being labeled as negative. However, we can easily recognize it as a poorly labeled sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "This *should* have been an amazingly funny movie...but it falls flat on its face. (In fact, I stopped watching it halfway through, which is something I rarely do...) -- Bill Murray plays Jack Corcoran, a second-rate motivational speaker who is bequeathed an elephant by his father (whom he had presumed to be dead before he was born) ; he then has one week to get the ponderous pachyderm across the country. His adventures on the way are only mildly amusing at best. Janeane Garofalo's considerable comedic talents go largely untapped. Anita Gillette is impressive in her small role as Jack's mother (who has a lot of explaining to do), and Pat Hingle stands out as a former circus associate of Jack's father. -- Perhaps the second half of the movie was better than the first, but I find that hard to believe..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(reviews_test.loc[22148].review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Application\n",
    "\n",
    "### Custom Reviews\n",
    "To use this model, we would store the model, along with the preprocessing vectorizers, and run the unseen texts through following pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = pd.Series(\"this movie very good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed.\n"
     ]
    }
   ],
   "source": [
    "unseen = preprocess.transform(unseen)       # Text preprocessing\n",
    "unseen = tfidf.transform(unseen).toarray()  # Feature engineering\n",
    "unseen = unseen[:,bestIndeces]              # Feature selection\n",
    "probability = model.predict(unseen)[0,0]  # Network feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19737606\n",
      "Negative!\n"
     ]
    }
   ],
   "source": [
    "print(probability)\n",
    "print(\"Positive!\") if probability > 0.5 else print(\"Negative!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
